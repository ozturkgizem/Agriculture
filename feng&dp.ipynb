{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQnsKrDdZuQWHdLjVlzlte",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ozturkgizem/Agriculture/blob/main/feng%26dp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV, cross_validate, train_test_split\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "pd.set_option('display.width', 500)"
      ],
      "metadata": {
        "id": "n0cnKFkuaeIM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "xp2HT3GVafBA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Crop_recommendation.csv\")"
      ],
      "metadata": {
        "id": "RDU96s8xaXY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FEATURE ENG & DATA PROCESSING**"
      ],
      "metadata": {
        "id": "C8YQVW5tGAQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
        "    \"\"\"\n",
        "\n",
        "    Veri setindeki kategorik, numerik ve kategorik fakat kardinal değişkenlerin isimlerini verir.\n",
        "    Not: Kategorik değişkenlerin içerisine numerik görünümlü kategorik değişkenler de dahildir.\n",
        "\n",
        "    Parameters\n",
        "    ------\n",
        "        dataframe: dataframe\n",
        "                Değişken isimleri alınmak istenilen dataframe\n",
        "        cat_th: int, optional\n",
        "                numerik fakat kategorik olan değişkenler için sınıf eşik değeri\n",
        "        car_th: int, optinal\n",
        "                kategorik fakat kardinal değişkenler için sınıf eşik değeri\n",
        "\n",
        "    Returns\n",
        "    ------\n",
        "        cat_cols: list\n",
        "                Kategorik değişken listesi\n",
        "        num_cols: list\n",
        "                Numerik değişken listesi\n",
        "        cat_but_car: list\n",
        "                Kategorik görünümlü kardinal değişken listesi\n",
        "\n",
        "    Examples\n",
        "    ------\n",
        "        import seaborn as sns\n",
        "        df = sns.load_dataset(\"iris\")\n",
        "        print(grab_col_names(df))\n",
        "\n",
        "\n",
        "    Notes\n",
        "    ------\n",
        "        cat_cols + num_cols + cat_but_car = toplam değişken sayısı\n",
        "        num_but_cat cat_cols'un içerisinde.\n",
        "        Return olan 3 liste toplamı toplam değişken sayısına eşittir: cat_cols + num_cols + cat_but_car = değişken sayısı\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # cat_cols, cat_but_car\n",
        "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
        "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n",
        "                   dataframe[col].dtypes != \"O\"]\n",
        "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n",
        "                   dataframe[col].dtypes == \"O\"]\n",
        "    cat_cols = cat_cols + num_but_cat\n",
        "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
        "\n",
        "    # num_cols\n",
        "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
        "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
        "\n",
        "    # print(f\"Observations: {dataframe.shape[0]}\")\n",
        "    # print(f\"Variables: {dataframe.shape[1]}\")\n",
        "    # print(f'cat_cols: {len(cat_cols)}')\n",
        "    # print(f'num_cols: {len(num_cols)}')\n",
        "    # print(f'cat_but_car: {len(cat_but_car)}')\n",
        "    # print(f'num_but_cat: {len(num_but_cat)}')\n",
        "    return cat_cols, num_cols, cat_but_car"
      ],
      "metadata": {
        "id": "ATFl7UCOHJqo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):\n",
        "    quartile1 = dataframe[col_name].quantile(q1)\n",
        "    quartile3 = dataframe[col_name].quantile(q3)\n",
        "    interquantile_range = quartile3 - quartile1\n",
        "    up_limit = quartile3 + 1.5 * interquantile_range\n",
        "    low_limit = quartile1 - 1.5 * interquantile_range\n",
        "    return low_limit, up_limit\n",
        "\n",
        "def check_outlier(dataframe, col_name):\n",
        "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
        "    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def replace_with_thresholds(dataframe, variable):\n",
        "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
        "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
        "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit"
      ],
      "metadata": {
        "id": "XGzFBF4xWdFK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_recommendation_data_prep(dataframe):\n",
        "\n",
        "    ##1: CROP SUITABILITY INDICES\n",
        "\n",
        "    cat_cols, num_cols, cat_but_car = grab_col_names(dataframe)\n",
        "\n",
        "    def crop_suitability_indices(crop, col):\n",
        "        low_limit, up_limit = outlier_thresholds(dataframe[dataframe[\"label\"] == crop], col)\n",
        "        dataframe.loc[(df[\"label\"] == crop) & (dataframe[col] >= low_limit) & (dataframe[col] <= up_limit), f\"NEW_{col.upper()}_OPTIMAL\"] = 1\n",
        "        dataframe.loc[(df[\"label\"] == crop) & (dataframe[col] < low_limit) | (dataframe[col] > up_limit), f\"NEW_{col.upper()}_OPTIMAL\"] = 0\n",
        "\n",
        "    for crop in df[\"label\"].unique():\n",
        "        for col in num_cols:\n",
        "            crop_suitability_indices(crop, col)\n",
        "\n",
        "    ##2: NUTRIENT BALANCE INDEX (NBI)\n",
        "\n",
        "    dataframe[\"N/K\"]= dataframe[\"N\"] / dataframe[\"K\"]\n",
        "    dataframe[\"N/P\"] = dataframe[\"N\"] / dataframe[\"P\"]\n",
        "    dataframe[\"P/K\"] = dataframe[\"P\"] / dataframe[\"K\"]\n",
        "\n",
        "    ratios = [\"N/K\",\"N/P\",\"P/K\"]\n",
        "    dataframe[ratios] = MinMaxScaler().fit_transform(dataframe[ratios])\n",
        "\n",
        "    dataframe[\"NEW_NBI\"] = np.sqrt(dataframe[\"N/K\"] * dataframe[\"N/P\"] * dataframe[\"P/K\"])\n",
        "    dataframe.drop(ratios, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "    ##3: CATEGORIZE BY PH LEVELS\n",
        "\n",
        "    dataframe.loc[dataframe[\"ph\"] < 7, \"NEW_PH_CAT\"] = \"acidic\"\n",
        "    dataframe.loc[dataframe[\"ph\"] > 7, \"NEW_PH_CAT\"] = \"alkaline\"\n",
        "    dataframe.loc[dataframe[\"ph\"] == 7, \"NEW_PH_CAT\"] = \"neutral\"\n",
        "    dataframe.loc[(dataframe[\"ph\"] >= 5.5) & (dataframe[\"ph\"] <= 6.5), \"NEW_PH_CAT\"] = \"optimal\"\n",
        "\n",
        "    ##4: CATEGORIZE BY RAINFALL\n",
        "    #sns.catplot(data=df, x='label', y=\"rainfall\", kind='box', height=10, aspect=22/8)\n",
        "    #plt.title(f\"{col}\", size=12)\n",
        "    #plt.xticks(rotation='vertical')\n",
        "    #plt.show()\n",
        "\n",
        "    #df[\"rainfall\"].describe([0.10,0.20,0.30,0.33,0.40,0.50,0.60,0.66,0.70,0.75,0.80,0.90,0.99])\n",
        "\n",
        "    dataframe[\"NEW_RAINFALL_CAT\"] = pd.cut(x=dataframe[\"rainfall\"], bins=[0, 44, 71, 111, 188, 300], labels=[\"extreme_low\", \"low\", \"medium\", \"high\", \"extreme_high\"])\n",
        "\n",
        "    ##5. ONE HOT ENCODER\n",
        "    def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n",
        "        dff = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first, dtype=int)\n",
        "        return dff\n",
        "\n",
        "    cat_cols, num_cols, cat_but_car = grab_col_names(dataframe)\n",
        "\n",
        "    dff = one_hot_encoder(dataframe, cat_cols, drop_first=True)\n",
        "\n",
        "    cat_cols, num_cols, cat_but_car = grab_col_names(dff)\n",
        "\n",
        "    X_scaled = StandardScaler().fit_transform(dff[num_cols])\n",
        "    dff[num_cols] = pd.DataFrame(X_scaled, columns=dff[num_cols].columns)\n",
        "\n",
        "    y = LabelEncoder().fit_transform(dff[\"label\"])\n",
        "    X = dff.drop([\"label\"], axis=1)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "7APPWjmCF_1j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = crop_recommendation_data_prep(df)"
      ],
      "metadata": {
        "id": "fYgMiVfKGbFQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def base_models(X, y, scoring=\"roc_auc\"):\n",
        "    print(\"Base Models....\")\n",
        "    classifiers = [('LR', LogisticRegression()),\n",
        "                   ('KNN', KNeighborsClassifier()),\n",
        "                   (\"SVC\", SVC()),\n",
        "                   (\"CART\", DecisionTreeClassifier()),\n",
        "                   (\"RF\", RandomForestClassifier()),\n",
        "                   ('Adaboost', AdaBoostClassifier()),\n",
        "                   ('GBM', GradientBoostingClassifier()),\n",
        "                   ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
        "                   ('LightGBM', LGBMClassifier()),\n",
        "                   # ('CatBoost', CatBoostClassifier(verbose=False))\n",
        "                   ]\n",
        "    for name, classifier in classifiers:\n",
        "        cv_results = cross_validate(classifier, X, y, cv=3, scoring=scoring)\n",
        "        print(f\"{scoring}: {round(cv_results['test_score'].mean(), 4)} ({name}) \")"
      ],
      "metadata": {
        "id": "Rl7e5Q3HGYo6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_models(X,y)"
      ],
      "metadata": {
        "id": "V-tptqG8GejS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}